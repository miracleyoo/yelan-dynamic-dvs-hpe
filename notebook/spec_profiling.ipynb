{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "488eace2",
   "metadata": {},
   "source": [
    "This notebook aims to measure the time saved by our modified scored unet architecture. You can find how to use the confidence score to save inference time by running the mask UNet less."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0217b8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "import glob\n",
    "import copy\n",
    "import time\n",
    "import torch\n",
    "import platform\n",
    "\n",
    "import os.path as op\n",
    "import numpy as np\n",
    "from dotdict import dotdict\n",
    "from matplotlib import pyplot as plt\n",
    "import pathlib2\n",
    "from pathlib2 import Path\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "sys.path.append('..')\n",
    "from scripts.data import DataInterface\n",
    "from scripts.model import ModelInteface, predict3d\n",
    "from scripts.utils import *\n",
    "from scripts.model.metrics import MPJPE\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d75bbdc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Directory:  e:\\GitHub\\dvs-hpe-light\\notebook\n",
      "Current Node:  Kirito\n",
      "Cuda availability:  True\n"
     ]
    }
   ],
   "source": [
    "# Get Basic Running Info\n",
    "print('Current Directory: ', os.getcwd())\n",
    "print('Current Node: ', platform.node())\n",
    "print('Cuda availability: ', torch.cuda.is_available())\n",
    "\n",
    "if platform.system() == 'Windows':\n",
    "    temp = pathlib2.PosixPath\n",
    "    pathlib2.PosixPath = pathlib2.WindowsPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e695216",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "frame_size = (260, 346)\n",
    "mpjpe = MPJPE()\n",
    "nidhp_root = r'L:\\DVS\\models\\hpe\\NiDHP'\n",
    "midhp_root = r'L:\\DVS\\models\\hpe\\MiDHP'\n",
    "mask_net_path = r'L:\\DVS\\models\\unet\\05-19-18-28-41\\checkpoints\\best-epoch=09-val_loss=0.021.ckpt'\n",
    "model_date_dict = {\n",
    "    'MiDHP': {\n",
    "        'w_cl':'05-25-16-19-04',\n",
    "        'const_time':'05-19-23-41-59',\n",
    "        'occlusion': '10-17-21-15-12'\n",
    "        },\n",
    "    'NiDHP': {\n",
    "        'w_cl':'06-01-16-13-56',\n",
    "        'const_time':'06-01-16-17-07',\n",
    "        'pretrain':'06-02-00-34-40'\n",
    "        }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67098d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_string():\n",
    "    \"\"\" Generate a time string from year to second.\n",
    "    \"\"\"\n",
    "    return time.strftime(\"%Y-%m-%d_%H-%M-%S\", time.localtime())\n",
    "\n",
    "def get_model_path(date, root=midhp_root, best=True):\n",
    "    model_subdir = op.join(root, date, 'checkpoints')\n",
    "    if best:\n",
    "        model_path = glob.glob(op.join(model_subdir, 'best*'))[0]\n",
    "    else:\n",
    "        model_path = op.join(model_subdir, 'last.ckpt')\n",
    "    return model_path\n",
    "\n",
    "def load_model(time_str='05-25-16-19-04', best=True, device='cuda', root=midhp_root):\n",
    "    model_path = get_model_path(time_str, root=root, best=True)\n",
    "    print(model_path)\n",
    "    model = ModelInteface.load_from_checkpoint(model_path, mask_net_path=mask_net_path, detailed_test_record=True)\n",
    "    model = model.to(device)\n",
    "    print('Using trained model: ', model_path)\n",
    "    return model\n",
    "\n",
    "def manual_load_data(data_path, idx=0):\n",
    "    reader = ToreSeqReader([data_path], labels_processed=False, percentile=90, redundant_labels=True)\n",
    "    print(\"Total tore number:\", reader.metas[0]['total_tore_count'])\n",
    "\n",
    "    b_x, b_y = reader.load_seq_by_index(0, idx)\n",
    "    tores = torch.tensor(b_x).float().to(device)\n",
    "    del b_y['name']\n",
    "    for k in b_y.keys():\n",
    "        b_y[k] = torch.tensor(b_y[k])\n",
    "    return b_x, b_y, tores\n",
    "\n",
    "def inference(batch, model, verbose=False):\n",
    "    b_x, b_y = batch\n",
    "    del b_y['name']\n",
    "    for k in b_y.keys():\n",
    "        b_y[k] = torch.tensor(b_y[k])\n",
    "    b_x = torch.tensor(b_x).float()\n",
    "    normed_pred_joints, masks = model.predict_step(b_x.unsqueeze(0).to(device))\n",
    "    normed_pred_joints = normed_pred_joints.cpu().detach()\n",
    "    del batch\n",
    "\n",
    "    if verbose:\n",
    "        print('Label Keys: ', b_y.keys())\n",
    "        print('Extrinsic:\\n', b_y['M'][0].numpy().round(2))\n",
    "        print('Intrinsic:\\n', b_y['camera'][0].numpy().round(2))\n",
    "    return normed_pred_joints, masks, b_x, b_y\n",
    "\n",
    "suf = lambda n: \"%d%s\"%(n,{1:\"st\",2:\"nd\",3:\"rd\"}.get(n if n<20 else n%10,\"th\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44cc37d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "frame_size = (260, 346)\n",
    "mpjpe = MPJPE()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0c123c",
   "metadata": {},
   "source": [
    "# Spec Measure & Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7d52afd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gg_idx(l, thres):\n",
    "    try:\n",
    "        return next(i for i,v in enumerate(l) if v<thres)\n",
    "    except:\n",
    "        return len(l)\n",
    "    \n",
    "def denormalize_skeleton_batch(model, normed_pred_joints, b_y):\n",
    "    pred_skcam = model.denormalize_predictions(normalized_predictions=normed_pred_joints, b_y=b_y)\n",
    "    pred_skori = np.array([reproject_xyz_onto_world_coord(pred_skcam[i], b_y['M'][i]).numpy() for i in range(16)])\n",
    "    return pred_skori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e3961238",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/gypsum/scratch1/zhongyangzha/DVS_HPE/ntore_dataset/synthetic/Venti_left_nature_stream/meta.json'\n",
    "\n",
    "human_name, camera_view = Path(data_path).parts[-2].split('_')[:2]\n",
    "mask_root = f'/gypsum/work1/trahman/zhongyangzha/dvs_hpe/ntore_dataset/masks_acc/{human_name}/{camera_view}_alpha'\n",
    "\n",
    "reader = ToreSeqReader([data_path], redundant_labels=True, labels_processed=True)\n",
    "mask_reader = MaskSeqReader(mask_root)\n",
    "batch = reader.get_pair_by_index(0,0)\n",
    "\n",
    "model = load_model(time_str=model_date_dict['MiDHP']['w_cl'], best=True, device='cuda', root=midhp_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75aa765",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = np.linspace(0.966,1,20)\n",
    "total_time_records = []\n",
    "mask_time_records = []\n",
    "hpe_time_records = []\n",
    "mpjpe_recorder = []\n",
    "final_number = reader.metas[0]['total_tore_count'] - (reader.metas[0]['total_tore_count'] % 16)\n",
    "\n",
    "for thres_idx, thres in enumerate(thresholds):\n",
    "    tic1 = time.time()\n",
    "    \n",
    "    # Mask Prediction\n",
    "    idx = 0\n",
    "    masks_selected = []\n",
    "    while True:\n",
    "        batch = reader.get_pair_by_index(0, idx)\n",
    "        tores, labels = batch\n",
    "\n",
    "        tores = torch.tensor(tores[np.newaxis,...]).float().to(device)\n",
    "        masks_pred, score_pred = model.model.mask_net(tores)\n",
    "        masks_pred = torch.sigmoid(masks_pred)\n",
    "        forward_num = max(1,get_gg_idx(score_pred.squeeze().cpu().detach(), thres))\n",
    "        masks_selected.extend([*masks_pred.cpu().detach().numpy()[:forward_num]])\n",
    "        idx += forward_num\n",
    "        if idx >= final_number:\n",
    "            masks_selected = masks_selected[:final_number]\n",
    "            break\n",
    "    \n",
    "    tic2 = time.time()\n",
    "    mask_time_records.append(tic2 - tic1)\n",
    "    \n",
    "    # HPE\n",
    "    mpjpe_acc=[]\n",
    "    for idx in range(final_number//16):\n",
    "        batch = reader.load_seq_by_index(0, idx*16)\n",
    "        tores, b_y = batch\n",
    "        del b_y['name']\n",
    "        for k in b_y.keys():\n",
    "            b_y[k] = torch.tensor(b_y[k])\n",
    "        tores = torch.tensor([tores]).float().to(device)\n",
    "        mask_input = torch.tensor(np.stack(masks_selected[idx*16:(idx+1)*16])).unsqueeze(1).float().to(device)\n",
    "        skeleton_ori = b_y['xyz']\n",
    "        normed_pred_joints, _ = model.predict_step(tores, mask_input=mask_input)\n",
    "        skeleton_pred = denormalize_skeleton_batch(model, normed_pred_joints.cpu().detach(), b_y)\n",
    "        mpjpe_batch = np.mean([torch.mean(mpjpe(torch.tensor(skeleton_pred), skeleton_ori.cpu().detach())).item()])\n",
    "        mpjpe_acc.append(mpjpe_batch)\n",
    "    \n",
    "    mpjpe_recorder.append(np.mean(mpjpe_acc))\n",
    "    \n",
    "    tic3 = time.time()\n",
    "    hpe_time_records.append(tic3-tic2)\n",
    "    total_time_records.append(tic3-tic1)\n",
    "    print(f'No.{thres_idx}, Threshold: {round(thres,3)}, Mask Pred Time: {round(mask_time_records[-1], 3)}, HPE Time: {round(hpe_time_records[-1],3)}, Total Time: {round(total_time_records[-1],3)}, Mean MPJPE: {round(mpjpe_recorder[-1],3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a80d1993",
   "metadata": {},
   "outputs": [],
   "source": [
    "mega_info_pack = {\n",
    "    'thresholds':thresholds,\n",
    "    'total_time_records': total_time_records,\n",
    "    'mask_time_records': mask_time_records,\n",
    "    'hpe_time_records': hpe_time_records,\n",
    "    'mpjpe_recorder': mpjpe_recorder\n",
    "}\n",
    "with open(\"./results/mega_info_pack_.yaml\", 'w') as f:\n",
    "    yaml.dump(mega_info_pack, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd037c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "\n",
    "width=700\n",
    "height=400\n",
    "x = thresholds\n",
    "mask_time_records = np.array(mask_time_records)\n",
    "total_time_records = np.array(total_time_records)\n",
    "mpjpe_recorder = np.array(mpjpe_recorder)\n",
    "y1 = (1-mask_time_records/mask_time_records.max())*100\n",
    "y2 = (1-total_time_records/total_time_records.max())*100\n",
    "y3 = (1 - mpjpe_recorder/mpjpe_recorder.max())*100\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=thresholds,\n",
    "    y=y1,\n",
    "    name=\"Mask Time Saving Percentage\"\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=thresholds,\n",
    "    y=y2,\n",
    "    name=\"Total Time Saving Percentage\"\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=x,\n",
    "    y=y3,\n",
    "    name=\"Performance Rising Percentage\"\n",
    "))\n",
    "\n",
    "fig.update_layout(width=width, height=height) #legend_title_text='Trend', \n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis_title=\"Confidence Score Threshold\",\n",
    "    yaxis_title=\"Percentage\",\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "pio.write_image(fig, op.join('./results', \"score-percentages.png\"), width=width, height=height, scale=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dvs_pose",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "bf281af68c64d7bfd4a480d951a167d187aaebbadc9f395b98054d241d697fc0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
